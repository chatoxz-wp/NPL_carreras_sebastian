{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010fcdba",
   "metadata": {},
   "source": [
    "# Enunciado\n",
    "\n",
    "Construir QA Bot basado en el ejemplo del traductor pero con un dataset QA.\n",
    "\n",
    "Algunos frameworks/librerías que traen modelos e interfaces preparadas para armar rápidamente un sistema basado en NLP:\n",
    "\n",
    "- DeepPavLov\n",
    "- Hugging Face\n",
    "- FastAI\n",
    "- ParlAI\n",
    "\n",
    "Recomendaciones:\n",
    "- MAX_VOCAB_SIZE = 8000\n",
    "- max_length ~ 10\n",
    "- Embeddings 300 Fasttext\n",
    "- n_units = 128\n",
    "- LSTM Dropout 0.2\n",
    "- Epochs 30~50\n",
    "\n",
    "Preguntas interesantes:\n",
    "- Do you read?\n",
    "- Do you have any pet?\n",
    "- Where are you from?\n",
    "\n",
    "__IMPORTANTE__: Recuerde para la entrega del ejercicio debe quedar registrado en el colab las preguntas y las respuestas del BOT para que podamos evaluar el desempeño final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849b1bc",
   "metadata": {},
   "source": [
    "# 1. Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d881e85",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c348e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import os\n",
    "import pickle\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d1a10",
   "metadata": {},
   "source": [
    "## Defino parametros recomendadas para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febad2d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee449fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (0.32.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Instalar la librería si no la tienes\n",
    "!pip install datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Descargar el dataset wiki_qa\n",
    "dataset = load_dataset(\"wiki_qa\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac5e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a pandas DataFrame para facilitar el manejo\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset)  # El split por defecto es 'train'\n",
    "\n",
    "# Extraer listas de preguntas y respuestas\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()# Agrega tokens explícitos como <start> y <end> en las respuestas antes de la tokenización:\n",
    "answers = [\"<start> \" + answer + \" <end>\" for answer in answers]\n",
    "\n",
    "# Asegura que solo haya un <start> y un <end> por respuesta\n",
    "def add_special_tokens(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('<start>', '').replace('<end>', '').strip()\n",
    "    return f\"<start> {text} <end>\"\n",
    "\n",
    "answers = [add_special_tokens(a) for a in answers]\n",
    "\n",
    "# Calcular las longitudes de las preguntas\n",
    "lengths_questions = [len(q.split()) for q in questions]\n",
    "# Calcular el percentil 95 para cada tipo de secuencia\n",
    "max_length_questions = int(np.percentile(lengths_questions, 95))\n",
    "lengths_answers = [len(a.split()) for a in answers]\n",
    "max_length_answers = int(np.percentile(lengths_answers, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64f97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 8000 #baje desde 5000 para mejorar la precisión\n",
    "#MAX_LENGTH = 12  # definida arriba con el percentil 95\n",
    "EMBEDDING_DIM = 300  # FastText\n",
    "N_UNITS = 128\n",
    "LSTM_DROPOUT = 0.2\n",
    "EPOCHS = 40  # Promedio recomendado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328cbb7",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af94a8",
   "metadata": {},
   "source": [
    "## Tokenización de preguntas y respuestas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e1553a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario (input): 4082\n",
      "Pregunta más larga: 23\n",
      "Palabras en el vocabulario (output): 32274\n",
      "Respuesta más larga: 167\n"
     ]
    }
   ],
   "source": [
    "#Vocabulario de entrada: 4083 palabras\n",
    "#Vocabulario de salida: 32275 palabras\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# Tokenizador para preguntas (inputs)\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(questions)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(questions)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario (input):\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(seq) for seq in input_integer_seq)\n",
    "print(\"Pregunta más larga:\", max_input_len)\n",
    "\n",
    "# Tokenizador para respuestas (outputs)\n",
    "#output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\\\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer = Tokenizer(\n",
    "    num_words=MAX_VOCAB_SIZE, \n",
    "    filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n',  # Quita '<' y '>' de los filtros\n",
    "    oov_token='<unk>'  # Opcional: token para palabras desconocidas\n",
    ")\n",
    "\n",
    "output_tokenizer.fit_on_texts(answers)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario (output):\", len(word2idx_outputs))\n",
    "\n",
    "max_output_len = max(len(seq) for seq in output_integer_seq)\n",
    "print(\"Respuesta más larga:\", max_output_len)\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)  # +1 para el token de palabra desconocida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e7f65",
   "metadata": {},
   "source": [
    "## Padding de secuencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8e367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences shape: (20360, 12)\n",
      "decoder_input_sequences shape: (20360, 46)\n"
     ]
    }
   ],
   "source": [
    "# Limitar longitudes si es necesario\n",
    "max_input_len = min(max_input_len, max_length_questions)\n",
    "max_output_len = min(max_output_len, max_length_answers)\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "decoder_input_sequences = pad_sequences(output_integer_seq, maxlen=max_output_len, padding='post')\n",
    "\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f345a2",
   "metadata": {},
   "source": [
    "## One-hot encoding de las salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb41d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_targets shape: (20360, 46, 8000)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "decoder_targets = to_categorical(decoder_input_sequences, num_classes=num_words_output)\n",
    "print(\"decoder_targets shape:\", decoder_targets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf608e3",
   "metadata": {},
   "source": [
    "## Descargar Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56f1073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo cc.en.300.vec ya existe, no se descarga ni descomprime.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"cc.en.300.vec\"):\n",
    "    if not os.path.exists(\"cc.en.300.vec.gz\"):\n",
    "        # Descargar solo si el archivo comprimido no existe\n",
    "        !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "    # Descomprimir solo si el archivo descomprimido no existe\n",
    "    !gunzip cc.en.300.vec.gz\n",
    "else:\n",
    "    print(\"El archivo cc.en.300.vec ya existe, no se descarga ni descomprime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b774ef7",
   "metadata": {},
   "source": [
    "# Preparear los embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f39d4",
   "metadata": {},
   "source": [
    "## Descargar y Descomprimir los Embeddings FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ef2190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando embeddings desde el archivo pickle...\n",
      "Cantidad de palabras en embeddings: 2000000\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_VEC_TXT = 'cc.en.300.vec'\n",
    "EMBEDDING_VEC_PKL = 'cc.en.300.vec.pkl'\n",
    "\n",
    "if os.path.exists(EMBEDDING_VEC_PKL):\n",
    "    print(\"Cargando embeddings desde el archivo pickle...\")\n",
    "    with open(EMBEDDING_VEC_PKL, 'rb') as f:\n",
    "        embedding_index = pickle.load(f)\n",
    "else:\n",
    "    print(\"Procesando archivo de texto de embeddings...\")\n",
    "    embedding_index = {}\n",
    "    with open(EMBEDDING_VEC_TXT, encoding='utf-8', errors='ignore') as f:\n",
    "        next(f)  # saltea la primera línea si tiene info de vocabulario\n",
    "        for line in f:\n",
    "            values = line.rstrip().split(' ')\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_index[word] = vector\n",
    "    # Guardar para la próxima vez\n",
    "    with open(EMBEDDING_VEC_PKL, 'wb') as f:\n",
    "        pickle.dump(embedding_index, f)\n",
    "    print(\"Embeddings guardados en archivo pickle.\")\n",
    "\n",
    "print(f\"Cantidad de palabras en embeddings: {len(embedding_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87b668",
   "metadata": {},
   "source": [
    "## Crear la Embedding Matrix para el Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1c1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    # Si la palabra no está, la fila queda en ceros (vector nulo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400fd8a4",
   "metadata": {},
   "source": [
    "## Verificar la Embedding Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a4c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_matrix shape: (4083, 300)\n",
      "Número de palabras sin embedding: 155\n"
     ]
    }
   ],
   "source": [
    "print('embedding_matrix shape:', embedding_matrix.shape)\n",
    "print('Número de palabras sin embedding:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9cc1c",
   "metadata": {},
   "source": [
    "## Definición del Modelo Seq2Seq (Encoder-Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5625b238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,224,900</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,000</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │ encoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ decoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8000</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032,000</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m1,224,900\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,024,000\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │    \u001b[38;5;34m219,648\u001b[0m │ encoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m), │    \u001b[38;5;34m131,584\u001b[0m │ decoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m8000\u001b[0m)  │  \u001b[38;5;34m1,032,000\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,632,132</span> (13.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,632,132\u001b[0m (13.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,407,232</span> (9.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,407,232\u001b[0m (9.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,224,900</span> (4.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,224,900\u001b[0m (4.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_len,), name='encoder_input') # Add name\n",
    "encoder_embedding = Embedding(\n",
    "    input_dim=nb_words,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False,\n",
    "    name='encoder_embedding' # Add name\n",
    ")(encoder_inputs)\n",
    "encoder_lstm = LSTM(N_UNITS, return_state=True, dropout=LSTM_DROPOUT, name='encoder_lstm') # Add name\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_len,), name='decoder_input') # Add name\n",
    "decoder_embedding = Embedding(\n",
    "    input_dim=num_words_output,\n",
    "    output_dim=N_UNITS,\n",
    "    name='decoder_embedding' # Add name\n",
    ")(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(N_UNITS, return_sequences=True, return_state=True, dropout=LSTM_DROPOUT, name='decoder_lstm') # Add name\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax', name='decoder_dense') # Add name\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Modelo final\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9ddd7",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "070653d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrenamos y guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409329e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.4358 - loss: 7.8084 - val_accuracy: 0.4811 - val_loss: 4.0062\n",
      "Epoch 2/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.4799 - loss: 3.8496 - val_accuracy: 0.4811 - val_loss: 3.4441\n",
      "Epoch 3/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.4823 - loss: 3.3704 - val_accuracy: 0.5021 - val_loss: 3.1547\n",
      "Epoch 4/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.5025 - loss: 3.1167 - val_accuracy: 0.5212 - val_loss: 3.0114\n",
      "Epoch 5/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.5314 - loss: 2.9777 - val_accuracy: 0.5533 - val_loss: 2.9123\n",
      "Epoch 6/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.5568 - loss: 2.8696 - val_accuracy: 0.6017 - val_loss: 2.7965\n",
      "Epoch 7/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.6058 - loss: 2.7567 - val_accuracy: 0.6384 - val_loss: 2.6545\n",
      "Epoch 8/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.6538 - loss: 2.6254 - val_accuracy: 0.6813 - val_loss: 2.5123\n",
      "Epoch 9/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.6824 - loss: 2.4682 - val_accuracy: 0.6969 - val_loss: 2.3802\n",
      "Epoch 10/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.7003 - loss: 2.3466 - val_accuracy: 0.7204 - val_loss: 2.2619\n",
      "Epoch 11/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.7195 - loss: 2.2348 - val_accuracy: 0.7335 - val_loss: 2.1546\n",
      "Epoch 12/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.7324 - loss: 2.1212 - val_accuracy: 0.7418 - val_loss: 2.0558\n",
      "Epoch 13/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7421 - loss: 2.0318 - val_accuracy: 0.7558 - val_loss: 1.9613\n",
      "Epoch 14/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.7555 - loss: 1.9325 - val_accuracy: 0.7668 - val_loss: 1.8678\n",
      "Epoch 15/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.7671 - loss: 1.8370 - val_accuracy: 0.7795 - val_loss: 1.7744\n",
      "Epoch 16/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.7813 - loss: 1.7286 - val_accuracy: 0.7929 - val_loss: 1.6819\n",
      "Epoch 17/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7920 - loss: 1.6523 - val_accuracy: 0.8054 - val_loss: 1.5907\n",
      "Epoch 18/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8076 - loss: 1.5379 - val_accuracy: 0.8173 - val_loss: 1.5032\n",
      "Epoch 19/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.8190 - loss: 1.4534 - val_accuracy: 0.8284 - val_loss: 1.4200\n",
      "Epoch 20/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8299 - loss: 1.3805 - val_accuracy: 0.8410 - val_loss: 1.3418\n",
      "Epoch 21/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.8428 - loss: 1.2972 - val_accuracy: 0.8524 - val_loss: 1.2698\n",
      "Epoch 22/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8555 - loss: 1.2159 - val_accuracy: 0.8616 - val_loss: 1.2033\n",
      "Epoch 23/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.8646 - loss: 1.1495 - val_accuracy: 0.8693 - val_loss: 1.1420\n",
      "Epoch 24/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.8729 - loss: 1.0844 - val_accuracy: 0.8765 - val_loss: 1.0863\n",
      "Epoch 25/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.8802 - loss: 1.0272 - val_accuracy: 0.8840 - val_loss: 1.0352\n",
      "Epoch 26/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8862 - loss: 0.9844 - val_accuracy: 0.8896 - val_loss: 0.9877\n",
      "Epoch 27/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - accuracy: 0.8938 - loss: 0.9218 - val_accuracy: 0.8943 - val_loss: 0.9446\n",
      "Epoch 28/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.8981 - loss: 0.8815 - val_accuracy: 0.8982 - val_loss: 0.9044\n",
      "Epoch 29/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9029 - loss: 0.8399 - val_accuracy: 0.9023 - val_loss: 0.8674\n",
      "Epoch 30/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9066 - loss: 0.8046 - val_accuracy: 0.9061 - val_loss: 0.8323\n",
      "Epoch 31/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9118 - loss: 0.7588 - val_accuracy: 0.9107 - val_loss: 0.8000\n",
      "Epoch 32/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9158 - loss: 0.7278 - val_accuracy: 0.9148 - val_loss: 0.7691\n",
      "Epoch 33/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9202 - loss: 0.6934 - val_accuracy: 0.9181 - val_loss: 0.7397\n",
      "Epoch 34/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9237 - loss: 0.6622 - val_accuracy: 0.9212 - val_loss: 0.7118\n",
      "Epoch 35/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9265 - loss: 0.6364 - val_accuracy: 0.9239 - val_loss: 0.6851\n",
      "Epoch 36/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9298 - loss: 0.6069 - val_accuracy: 0.9267 - val_loss: 0.6595\n",
      "Epoch 37/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.9330 - loss: 0.5775 - val_accuracy: 0.9293 - val_loss: 0.6349\n",
      "Epoch 38/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.9361 - loss: 0.5486 - val_accuracy: 0.9318 - val_loss: 0.6117\n",
      "Epoch 39/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.9391 - loss: 0.5227 - val_accuracy: 0.9344 - val_loss: 0.5891\n",
      "Epoch 40/40\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9418 - loss: 0.4999 - val_accuracy: 0.9367 - val_loss: 0.5676\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    batch_size=512,\n",
    "    epochs=EPOCHS,  # Puedes ajustar entre 30 y 50 según recursos y overfitting\n",
    "    validation_split=0.2\n",
    ")\n",
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c5284",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e716322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count, y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count, y=hist.history['val_accuracy'], label='valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2402288",
   "metadata": {},
   "source": [
    "# Prueba del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf9dd3",
   "metadata": {},
   "source": [
    "## Defino el modelo del encoder y del decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d99b5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# --- Encoder de inferencia ---\n",
    "# We create new Input tensors for the inference model, but use the trained layers\n",
    "encoder_inf_inputs = Input(shape=(max_input_len,), name='encoder_inf_input')\n",
    "\n",
    "# Get the trained layers from the original model by name\n",
    "encoder_embedding_layer_inf = model.get_layer('encoder_embedding')\n",
    "encoder_lstm_layer_inf = model.get_layer('encoder_lstm')\n",
    "\n",
    "# Connect the inference input through the trained encoder layers\n",
    "encoder_embedding_output_inf = encoder_embedding_layer_inf(encoder_inf_inputs)\n",
    "_, state_h_inf, state_c_inf = encoder_lstm_layer_inf(encoder_embedding_output_inf)\n",
    "encoder_states_inf = [state_h_inf, state_c_inf]\n",
    "\n",
    "# Define the encoder inference model\n",
    "encoder_model = Model(encoder_inf_inputs, encoder_states_inf)\n",
    "\n",
    "# --- Decoder de inferencia ---\n",
    "# Inputs to the decoder inference model: [one token input, state_h from previous step, state_c from previous step]\n",
    "decoder_state_input_h_inf = Input(shape=(N_UNITS,), name='decoder_state_input_h_inf')\n",
    "decoder_state_input_c_inf = Input(shape=(N_UNITS,), name='decoder_state_input_c_inf')\n",
    "decoder_states_inputs_inf = [decoder_state_input_h_inf, decoder_state_input_c_inf]\n",
    "\n",
    "decoder_inputs_single_inf = Input(shape=(1,), name='decoder_input_single_inf') # Input shape is (batch_size, 1)\n",
    "\n",
    "# Get the trained layers for the decoder by name\n",
    "decoder_embedding_layer_inf = model.get_layer('decoder_embedding')\n",
    "decoder_lstm_layer_inf = model.get_layer('decoder_lstm')\n",
    "decoder_dense_layer_inf = model.get_layer('decoder_dense')\n",
    "\n",
    "# Connect the inference inputs through the trained decoder layers\n",
    "decoder_inputs_single_x_inf = decoder_embedding_layer_inf(decoder_inputs_single_inf) # Output shape (None, 1, N_UNITS)\n",
    "\n",
    "# Note: decoder_lstm_layer_inf is the trained LSTM layer instance\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm_layer_inf(\n",
    "    decoder_inputs_single_x_inf,\n",
    "    initial_state=decoder_states_inputs_inf # Pass the states from the previous time step\n",
    ")\n",
    "\n",
    "# Pass the LSTM output through the trained dense layer\n",
    "decoder_outputs_inf = decoder_dense_layer_inf(decoder_outputs_inf) # Output shape (None, 1, num_words_output)\n",
    "\n",
    "# Define the decoder inference model\n",
    "# Inputs: [single token input] + [previous state H, previous state C]\n",
    "# Outputs: [predicted token distribution] + [next state H, next state C]\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single_inf] + decoder_states_inputs_inf,\n",
    "    [decoder_outputs_inf] + [state_h_inf, state_c_inf]\n",
    ")\n",
    "\n",
    "# Optional: Print summaries to verify they are built correctly\n",
    "# encoder_model.summary()\n",
    "# decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeafe39",
   "metadata": {},
   "source": [
    "## Preparar los conversores de índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "932d22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_input = {v: k for k, v in word2idx_inputs.items()}\n",
    "idx2word_output = {v: k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9f8d7",
   "metadata": {},
   "source": [
    "## Función de inferencia (QA Bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2fb7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question_text):\n",
    "    # Tokenizar y paddear la pregunta\n",
    "    seq = input_tokenizer.texts_to_sequences([question_text])\n",
    "    # Ensure seq is a list of lists, pad_sequences expects this format\n",
    "    if not isinstance(seq, list):\n",
    "        seq = [seq]\n",
    "    seq = pad_sequences(seq, maxlen=max_input_len) # Shape (1, max_input_len)\n",
    "\n",
    "    # Obtener los estados del encoder\n",
    "    # This call to encoder_model.predict should now work with the correct input shape\n",
    "    states_value = encoder_model.predict(seq, verbose=0) # Add verbose=0 to hide progress bar\n",
    "\n",
    "    # Initialize sequence of input to the decoder. Start with the start token.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    start_token_id = word2idx_outputs.get('<start>', 0) # Get ID for <start>, default to 0 if not found\n",
    "    if start_token_id == 0:\n",
    "         print(\"Warning: '<start>' token not found in output vocabulary.\")\n",
    "         # Handle this case - maybe return an error or a default response\n",
    "         return \"Error: Decoder start token not found.\"\n",
    "    target_seq[0, 0] = start_token_id\n",
    "\n",
    "    # Get the end token ID\n",
    "    end_token_id = word2idx_outputs.get('<end>', -1) # Get ID for <end>, default to -1 (unlikely index)\n",
    "\n",
    "    output_sentence = []\n",
    "    # Max length for generated sequence to prevent infinite loops\n",
    "    for _ in range(max_output_len):\n",
    "        # Predict next token and get the next states\n",
    "        # Pass the single token input and the states from the previous step\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "\n",
    "        # Get the predicted token index. The output is (batch_size, 1, vocab_size)\n",
    "        # We need the probabilities for the single time step (index 0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Look up the word\n",
    "        sampled_word = idx2word_output.get(sampled_token_index, '<unk>') # Default to <unk>\n",
    "\n",
    "        # Check if it's the end token or max length reached\n",
    "        if sampled_token_index == end_token_id:\n",
    "            break\n",
    "\n",
    "        # Avoid adding the start token, padding, or unknown tokens to the output string\n",
    "        if sampled_word not in ['<start>', '<end>', '<pad>', '<unk>']:\n",
    "             output_sentence.append(sampled_word)\n",
    "        # Optionally, you might want to include <unk> if it's important\n",
    "\n",
    "        # Update states for the next time step\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Update target sequence (input for the next time step is the token we just predicted)\n",
    "        target_seq = np.zeros((1, 1)) # Create a new input sequence (shape (1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index # Set the input to the predicted token index\n",
    "\n",
    "    # Join the collected words into a sentence\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dcb1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question_text):\n",
    "   # Tokenizar y paddear la pregunta\n",
    "    seq = input_tokenizer.texts_to_sequences([question_text])\n",
    "    # Ensure seq is a list of lists, pad_sequences expects this format\n",
    "    if not isinstance(seq, list):\n",
    "        seq = [seq]\n",
    "    seq = pad_sequences(seq, maxlen=max_input_len) # Shape (1, max_input_len)\n",
    "\n",
    "    # Obtener los estados del encoder\n",
    "    # This call to encoder_model.predict should now work with the correct input shape\n",
    "    states_value = encoder_model.predict(seq, verbose=0) # Add verbose=0 to hide progress bar\n",
    "\n",
    "    # Initialize sequence of input to the decoder. Start with the start token.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    start_token_id = word2idx_outputs.get('<start>', 0) # Get ID for <start>, default to 0 if not found\n",
    "    if start_token_id == 0:\n",
    "         print(\"Warning: '<start>' token not found in output vocabulary.\")\n",
    "         # Handle this case - maybe return an error or a default response\n",
    "         return \"Error: Decoder start token not found.\"\n",
    "    target_seq[0, 0] = start_token_id\n",
    "\n",
    "    # Get the end token ID\n",
    "    end_token_id = word2idx_outputs.get('<end>', -1) # Get ID for <end>, default to -1 (unlikely index)\n",
    "\n",
    "    output_sentence = []\n",
    "    # Max length for generated sequence to prevent infinite loops\n",
    "    for i in range(max_output_len): # Added index 'i' for debugging step number\n",
    "        # Predict next token and get the next states\n",
    "        # Pass the single token input and the states from the previous step\n",
    "        print(f\"Step {i+1}: Decoding with input token {target_seq[0,0]} (word: {idx2word_output.get(target_seq[0,0], 'N/A')})\") # Debug print\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "\n",
    "        # Get the predicted token index. The output is (batch_size, 1, vocab_size)\n",
    "        # We need the probabilities for the single time step (index 0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
    "        print(f\"Step {i+1}: Predicted token index: {sampled_token_index}\") # Debug print\n",
    "\n",
    "        # Look up the word\n",
    "        sampled_word = idx2word_output.get(sampled_token_index, '<unk>') # Default to <unk>\n",
    "        print(f\"Step {i+1}: Predicted word: {sampled_word}\") # Debug print\n",
    "\n",
    "        # Check if it's the end token or max length reached\n",
    "        if sampled_token_index == end_token_id:\n",
    "            print(f\"Step {i+1}: Predicted <end> token. Breaking loop.\") # Debug print\n",
    "            break\n",
    "\n",
    "        # Avoid adding the start token, padding, or unknown tokens to the output string\n",
    "        if sampled_word not in ['<start>', '<end>', '<pad>', '<unk>']:\n",
    "             output_sentence.append(sampled_word)\n",
    "\n",
    "        # Update states for the next time step\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Update target sequence (input for the next time step is the token we just predicted)\n",
    "        target_seq = np.zeros((1, 1)) # Create a new input sequence (shape (1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index # Set the input to the predicted token index\n",
    "\n",
    "    # Join the collected words into a sentence\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de252ddd",
   "metadata": {},
   "source": [
    "## Probar las preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43a72225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How can I reset my password?\n",
      "Step 1: Decoding with input token 3.0 (word: <start>)\n",
      "Step 1: Predicted token index: 3\n",
      "Step 1: Predicted word: <start>\n",
      "Step 2: Decoding with input token 3.0 (word: <start>)\n",
      "Step 2: Predicted token index: 3\n",
      "Step 2: Predicted word: <start>\n",
      "Step 3: Decoding with input token 3.0 (word: <start>)\n",
      "Step 3: Predicted token index: 3\n",
      "Step 3: Predicted word: <start>\n",
      "Step 4: Decoding with input token 3.0 (word: <start>)\n",
      "Step 4: Predicted token index: 3\n",
      "Step 4: Predicted word: <start>\n",
      "Step 5: Decoding with input token 3.0 (word: <start>)\n",
      "Step 5: Predicted token index: 0\n",
      "Step 5: Predicted word: <unk>\n",
      "Step 6: Decoding with input token 0.0 (word: N/A)\n",
      "Step 6: Predicted token index: 0\n",
      "Step 6: Predicted word: <unk>\n",
      "Step 7: Decoding with input token 0.0 (word: N/A)\n",
      "Step 7: Predicted token index: 0\n",
      "Step 7: Predicted word: <unk>\n",
      "Step 8: Decoding with input token 0.0 (word: N/A)\n",
      "Step 8: Predicted token index: 0\n",
      "Step 8: Predicted word: <unk>\n",
      "Step 9: Decoding with input token 0.0 (word: N/A)\n",
      "Step 9: Predicted token index: 0\n",
      "Step 9: Predicted word: <unk>\n",
      "Step 10: Decoding with input token 0.0 (word: N/A)\n",
      "Step 10: Predicted token index: 0\n",
      "Step 10: Predicted word: <unk>\n",
      "Step 11: Decoding with input token 0.0 (word: N/A)\n",
      "Step 11: Predicted token index: 0\n",
      "Step 11: Predicted word: <unk>\n",
      "Step 12: Decoding with input token 0.0 (word: N/A)\n",
      "Step 12: Predicted token index: 0\n",
      "Step 12: Predicted word: <unk>\n",
      "Step 13: Decoding with input token 0.0 (word: N/A)\n",
      "Step 13: Predicted token index: 0\n",
      "Step 13: Predicted word: <unk>\n",
      "Step 14: Decoding with input token 0.0 (word: N/A)\n",
      "Step 14: Predicted token index: 0\n",
      "Step 14: Predicted word: <unk>\n",
      "Step 15: Decoding with input token 0.0 (word: N/A)\n",
      "Step 15: Predicted token index: 0\n",
      "Step 15: Predicted word: <unk>\n",
      "Step 16: Decoding with input token 0.0 (word: N/A)\n",
      "Step 16: Predicted token index: 0\n",
      "Step 16: Predicted word: <unk>\n",
      "Step 17: Decoding with input token 0.0 (word: N/A)\n",
      "Step 17: Predicted token index: 0\n",
      "Step 17: Predicted word: <unk>\n",
      "Step 18: Decoding with input token 0.0 (word: N/A)\n",
      "Step 18: Predicted token index: 0\n",
      "Step 18: Predicted word: <unk>\n",
      "Step 19: Decoding with input token 0.0 (word: N/A)\n",
      "Step 19: Predicted token index: 0\n",
      "Step 19: Predicted word: <unk>\n",
      "Step 20: Decoding with input token 0.0 (word: N/A)\n",
      "Step 20: Predicted token index: 0\n",
      "Step 20: Predicted word: <unk>\n",
      "Step 21: Decoding with input token 0.0 (word: N/A)\n",
      "Step 21: Predicted token index: 0\n",
      "Step 21: Predicted word: <unk>\n",
      "Step 22: Decoding with input token 0.0 (word: N/A)\n",
      "Step 22: Predicted token index: 0\n",
      "Step 22: Predicted word: <unk>\n",
      "Step 23: Decoding with input token 0.0 (word: N/A)\n",
      "Step 23: Predicted token index: 0\n",
      "Step 23: Predicted word: <unk>\n",
      "Step 24: Decoding with input token 0.0 (word: N/A)\n",
      "Step 24: Predicted token index: 0\n",
      "Step 24: Predicted word: <unk>\n",
      "Step 25: Decoding with input token 0.0 (word: N/A)\n",
      "Step 25: Predicted token index: 0\n",
      "Step 25: Predicted word: <unk>\n",
      "Step 26: Decoding with input token 0.0 (word: N/A)\n",
      "Step 26: Predicted token index: 0\n",
      "Step 26: Predicted word: <unk>\n",
      "Step 27: Decoding with input token 0.0 (word: N/A)\n",
      "Step 27: Predicted token index: 0\n",
      "Step 27: Predicted word: <unk>\n",
      "Step 28: Decoding with input token 0.0 (word: N/A)\n",
      "Step 28: Predicted token index: 0\n",
      "Step 28: Predicted word: <unk>\n",
      "Step 29: Decoding with input token 0.0 (word: N/A)\n",
      "Step 29: Predicted token index: 0\n",
      "Step 29: Predicted word: <unk>\n",
      "Step 30: Decoding with input token 0.0 (word: N/A)\n",
      "Step 30: Predicted token index: 0\n",
      "Step 30: Predicted word: <unk>\n",
      "Step 31: Decoding with input token 0.0 (word: N/A)\n",
      "Step 31: Predicted token index: 0\n",
      "Step 31: Predicted word: <unk>\n",
      "Step 32: Decoding with input token 0.0 (word: N/A)\n",
      "Step 32: Predicted token index: 0\n",
      "Step 32: Predicted word: <unk>\n",
      "Step 33: Decoding with input token 0.0 (word: N/A)\n",
      "Step 33: Predicted token index: 0\n",
      "Step 33: Predicted word: <unk>\n",
      "Step 34: Decoding with input token 0.0 (word: N/A)\n",
      "Step 34: Predicted token index: 0\n",
      "Step 34: Predicted word: <unk>\n",
      "Step 35: Decoding with input token 0.0 (word: N/A)\n",
      "Step 35: Predicted token index: 0\n",
      "Step 35: Predicted word: <unk>\n",
      "Step 36: Decoding with input token 0.0 (word: N/A)\n",
      "Step 36: Predicted token index: 0\n",
      "Step 36: Predicted word: <unk>\n",
      "Step 37: Decoding with input token 0.0 (word: N/A)\n",
      "Step 37: Predicted token index: 0\n",
      "Step 37: Predicted word: <unk>\n",
      "Step 38: Decoding with input token 0.0 (word: N/A)\n",
      "Step 38: Predicted token index: 0\n",
      "Step 38: Predicted word: <unk>\n",
      "Step 39: Decoding with input token 0.0 (word: N/A)\n",
      "Step 39: Predicted token index: 0\n",
      "Step 39: Predicted word: <unk>\n",
      "Step 40: Decoding with input token 0.0 (word: N/A)\n",
      "Step 40: Predicted token index: 0\n",
      "Step 40: Predicted word: <unk>\n",
      "Step 41: Decoding with input token 0.0 (word: N/A)\n",
      "Step 41: Predicted token index: 0\n",
      "Step 41: Predicted word: <unk>\n",
      "Step 42: Decoding with input token 0.0 (word: N/A)\n",
      "Step 42: Predicted token index: 0\n",
      "Step 42: Predicted word: <unk>\n",
      "Step 43: Decoding with input token 0.0 (word: N/A)\n",
      "Step 43: Predicted token index: 0\n",
      "Step 43: Predicted word: <unk>\n",
      "Step 44: Decoding with input token 0.0 (word: N/A)\n",
      "Step 44: Predicted token index: 0\n",
      "Step 44: Predicted word: <unk>\n",
      "Step 45: Decoding with input token 0.0 (word: N/A)\n",
      "Step 45: Predicted token index: 0\n",
      "Step 45: Predicted word: <unk>\n",
      "Step 46: Decoding with input token 0.0 (word: N/A)\n",
      "Step 46: Predicted token index: 0\n",
      "Step 46: Predicted word: <unk>\n",
      "A: \n",
      "------------------------------\n",
      "Q: What payment methods do you accept?\n",
      "Step 1: Decoding with input token 3.0 (word: <start>)\n",
      "Step 1: Predicted token index: 3\n",
      "Step 1: Predicted word: <start>\n",
      "Step 2: Decoding with input token 3.0 (word: <start>)\n",
      "Step 2: Predicted token index: 3\n",
      "Step 2: Predicted word: <start>\n",
      "Step 3: Decoding with input token 3.0 (word: <start>)\n",
      "Step 3: Predicted token index: 3\n",
      "Step 3: Predicted word: <start>\n",
      "Step 4: Decoding with input token 3.0 (word: <start>)\n",
      "Step 4: Predicted token index: 3\n",
      "Step 4: Predicted word: <start>\n",
      "Step 5: Decoding with input token 3.0 (word: <start>)\n",
      "Step 5: Predicted token index: 0\n",
      "Step 5: Predicted word: <unk>\n",
      "Step 6: Decoding with input token 0.0 (word: N/A)\n",
      "Step 6: Predicted token index: 0\n",
      "Step 6: Predicted word: <unk>\n",
      "Step 7: Decoding with input token 0.0 (word: N/A)\n",
      "Step 7: Predicted token index: 0\n",
      "Step 7: Predicted word: <unk>\n",
      "Step 8: Decoding with input token 0.0 (word: N/A)\n",
      "Step 8: Predicted token index: 0\n",
      "Step 8: Predicted word: <unk>\n",
      "Step 9: Decoding with input token 0.0 (word: N/A)\n",
      "Step 9: Predicted token index: 0\n",
      "Step 9: Predicted word: <unk>\n",
      "Step 10: Decoding with input token 0.0 (word: N/A)\n",
      "Step 10: Predicted token index: 0\n",
      "Step 10: Predicted word: <unk>\n",
      "Step 11: Decoding with input token 0.0 (word: N/A)\n",
      "Step 11: Predicted token index: 0\n",
      "Step 11: Predicted word: <unk>\n",
      "Step 12: Decoding with input token 0.0 (word: N/A)\n",
      "Step 12: Predicted token index: 0\n",
      "Step 12: Predicted word: <unk>\n",
      "Step 13: Decoding with input token 0.0 (word: N/A)\n",
      "Step 13: Predicted token index: 0\n",
      "Step 13: Predicted word: <unk>\n",
      "Step 14: Decoding with input token 0.0 (word: N/A)\n",
      "Step 14: Predicted token index: 0\n",
      "Step 14: Predicted word: <unk>\n",
      "Step 15: Decoding with input token 0.0 (word: N/A)\n",
      "Step 15: Predicted token index: 0\n",
      "Step 15: Predicted word: <unk>\n",
      "Step 16: Decoding with input token 0.0 (word: N/A)\n",
      "Step 16: Predicted token index: 0\n",
      "Step 16: Predicted word: <unk>\n",
      "Step 17: Decoding with input token 0.0 (word: N/A)\n",
      "Step 17: Predicted token index: 0\n",
      "Step 17: Predicted word: <unk>\n",
      "Step 18: Decoding with input token 0.0 (word: N/A)\n",
      "Step 18: Predicted token index: 0\n",
      "Step 18: Predicted word: <unk>\n",
      "Step 19: Decoding with input token 0.0 (word: N/A)\n",
      "Step 19: Predicted token index: 0\n",
      "Step 19: Predicted word: <unk>\n",
      "Step 20: Decoding with input token 0.0 (word: N/A)\n",
      "Step 20: Predicted token index: 0\n",
      "Step 20: Predicted word: <unk>\n",
      "Step 21: Decoding with input token 0.0 (word: N/A)\n",
      "Step 21: Predicted token index: 0\n",
      "Step 21: Predicted word: <unk>\n",
      "Step 22: Decoding with input token 0.0 (word: N/A)\n",
      "Step 22: Predicted token index: 0\n",
      "Step 22: Predicted word: <unk>\n",
      "Step 23: Decoding with input token 0.0 (word: N/A)\n",
      "Step 23: Predicted token index: 0\n",
      "Step 23: Predicted word: <unk>\n",
      "Step 24: Decoding with input token 0.0 (word: N/A)\n",
      "Step 24: Predicted token index: 0\n",
      "Step 24: Predicted word: <unk>\n",
      "Step 25: Decoding with input token 0.0 (word: N/A)\n",
      "Step 25: Predicted token index: 0\n",
      "Step 25: Predicted word: <unk>\n",
      "Step 26: Decoding with input token 0.0 (word: N/A)\n",
      "Step 26: Predicted token index: 0\n",
      "Step 26: Predicted word: <unk>\n",
      "Step 27: Decoding with input token 0.0 (word: N/A)\n",
      "Step 27: Predicted token index: 0\n",
      "Step 27: Predicted word: <unk>\n",
      "Step 28: Decoding with input token 0.0 (word: N/A)\n",
      "Step 28: Predicted token index: 0\n",
      "Step 28: Predicted word: <unk>\n",
      "Step 29: Decoding with input token 0.0 (word: N/A)\n",
      "Step 29: Predicted token index: 0\n",
      "Step 29: Predicted word: <unk>\n",
      "Step 30: Decoding with input token 0.0 (word: N/A)\n",
      "Step 30: Predicted token index: 0\n",
      "Step 30: Predicted word: <unk>\n",
      "Step 31: Decoding with input token 0.0 (word: N/A)\n",
      "Step 31: Predicted token index: 0\n",
      "Step 31: Predicted word: <unk>\n",
      "Step 32: Decoding with input token 0.0 (word: N/A)\n",
      "Step 32: Predicted token index: 0\n",
      "Step 32: Predicted word: <unk>\n",
      "Step 33: Decoding with input token 0.0 (word: N/A)\n",
      "Step 33: Predicted token index: 0\n",
      "Step 33: Predicted word: <unk>\n",
      "Step 34: Decoding with input token 0.0 (word: N/A)\n",
      "Step 34: Predicted token index: 0\n",
      "Step 34: Predicted word: <unk>\n",
      "Step 35: Decoding with input token 0.0 (word: N/A)\n",
      "Step 35: Predicted token index: 0\n",
      "Step 35: Predicted word: <unk>\n",
      "Step 36: Decoding with input token 0.0 (word: N/A)\n",
      "Step 36: Predicted token index: 0\n",
      "Step 36: Predicted word: <unk>\n",
      "Step 37: Decoding with input token 0.0 (word: N/A)\n",
      "Step 37: Predicted token index: 0\n",
      "Step 37: Predicted word: <unk>\n",
      "Step 38: Decoding with input token 0.0 (word: N/A)\n",
      "Step 38: Predicted token index: 0\n",
      "Step 38: Predicted word: <unk>\n",
      "Step 39: Decoding with input token 0.0 (word: N/A)\n",
      "Step 39: Predicted token index: 0\n",
      "Step 39: Predicted word: <unk>\n",
      "Step 40: Decoding with input token 0.0 (word: N/A)\n",
      "Step 40: Predicted token index: 0\n",
      "Step 40: Predicted word: <unk>\n",
      "Step 41: Decoding with input token 0.0 (word: N/A)\n",
      "Step 41: Predicted token index: 0\n",
      "Step 41: Predicted word: <unk>\n",
      "Step 42: Decoding with input token 0.0 (word: N/A)\n",
      "Step 42: Predicted token index: 0\n",
      "Step 42: Predicted word: <unk>\n",
      "Step 43: Decoding with input token 0.0 (word: N/A)\n",
      "Step 43: Predicted token index: 0\n",
      "Step 43: Predicted word: <unk>\n",
      "Step 44: Decoding with input token 0.0 (word: N/A)\n",
      "Step 44: Predicted token index: 0\n",
      "Step 44: Predicted word: <unk>\n",
      "Step 45: Decoding with input token 0.0 (word: N/A)\n",
      "Step 45: Predicted token index: 0\n",
      "Step 45: Predicted word: <unk>\n",
      "Step 46: Decoding with input token 0.0 (word: N/A)\n",
      "Step 46: Predicted token index: 0\n",
      "Step 46: Predicted word: <unk>\n",
      "A: \n",
      "------------------------------\n",
      "Q: How do I update my account information?\n",
      "Step 1: Decoding with input token 3.0 (word: <start>)\n",
      "Step 1: Predicted token index: 3\n",
      "Step 1: Predicted word: <start>\n",
      "Step 2: Decoding with input token 3.0 (word: <start>)\n",
      "Step 2: Predicted token index: 3\n",
      "Step 2: Predicted word: <start>\n",
      "Step 3: Decoding with input token 3.0 (word: <start>)\n",
      "Step 3: Predicted token index: 3\n",
      "Step 3: Predicted word: <start>\n",
      "Step 4: Decoding with input token 3.0 (word: <start>)\n",
      "Step 4: Predicted token index: 3\n",
      "Step 4: Predicted word: <start>\n",
      "Step 5: Decoding with input token 3.0 (word: <start>)\n",
      "Step 5: Predicted token index: 0\n",
      "Step 5: Predicted word: <unk>\n",
      "Step 6: Decoding with input token 0.0 (word: N/A)\n",
      "Step 6: Predicted token index: 0\n",
      "Step 6: Predicted word: <unk>\n",
      "Step 7: Decoding with input token 0.0 (word: N/A)\n",
      "Step 7: Predicted token index: 0\n",
      "Step 7: Predicted word: <unk>\n",
      "Step 8: Decoding with input token 0.0 (word: N/A)\n",
      "Step 8: Predicted token index: 0\n",
      "Step 8: Predicted word: <unk>\n",
      "Step 9: Decoding with input token 0.0 (word: N/A)\n",
      "Step 9: Predicted token index: 0\n",
      "Step 9: Predicted word: <unk>\n",
      "Step 10: Decoding with input token 0.0 (word: N/A)\n",
      "Step 10: Predicted token index: 0\n",
      "Step 10: Predicted word: <unk>\n",
      "Step 11: Decoding with input token 0.0 (word: N/A)\n",
      "Step 11: Predicted token index: 0\n",
      "Step 11: Predicted word: <unk>\n",
      "Step 12: Decoding with input token 0.0 (word: N/A)\n",
      "Step 12: Predicted token index: 0\n",
      "Step 12: Predicted word: <unk>\n",
      "Step 13: Decoding with input token 0.0 (word: N/A)\n",
      "Step 13: Predicted token index: 0\n",
      "Step 13: Predicted word: <unk>\n",
      "Step 14: Decoding with input token 0.0 (word: N/A)\n",
      "Step 14: Predicted token index: 0\n",
      "Step 14: Predicted word: <unk>\n",
      "Step 15: Decoding with input token 0.0 (word: N/A)\n",
      "Step 15: Predicted token index: 0\n",
      "Step 15: Predicted word: <unk>\n",
      "Step 16: Decoding with input token 0.0 (word: N/A)\n",
      "Step 16: Predicted token index: 0\n",
      "Step 16: Predicted word: <unk>\n",
      "Step 17: Decoding with input token 0.0 (word: N/A)\n",
      "Step 17: Predicted token index: 0\n",
      "Step 17: Predicted word: <unk>\n",
      "Step 18: Decoding with input token 0.0 (word: N/A)\n",
      "Step 18: Predicted token index: 0\n",
      "Step 18: Predicted word: <unk>\n",
      "Step 19: Decoding with input token 0.0 (word: N/A)\n",
      "Step 19: Predicted token index: 0\n",
      "Step 19: Predicted word: <unk>\n",
      "Step 20: Decoding with input token 0.0 (word: N/A)\n",
      "Step 20: Predicted token index: 0\n",
      "Step 20: Predicted word: <unk>\n",
      "Step 21: Decoding with input token 0.0 (word: N/A)\n",
      "Step 21: Predicted token index: 0\n",
      "Step 21: Predicted word: <unk>\n",
      "Step 22: Decoding with input token 0.0 (word: N/A)\n",
      "Step 22: Predicted token index: 0\n",
      "Step 22: Predicted word: <unk>\n",
      "Step 23: Decoding with input token 0.0 (word: N/A)\n",
      "Step 23: Predicted token index: 0\n",
      "Step 23: Predicted word: <unk>\n",
      "Step 24: Decoding with input token 0.0 (word: N/A)\n",
      "Step 24: Predicted token index: 0\n",
      "Step 24: Predicted word: <unk>\n",
      "Step 25: Decoding with input token 0.0 (word: N/A)\n",
      "Step 25: Predicted token index: 0\n",
      "Step 25: Predicted word: <unk>\n",
      "Step 26: Decoding with input token 0.0 (word: N/A)\n",
      "Step 26: Predicted token index: 0\n",
      "Step 26: Predicted word: <unk>\n",
      "Step 27: Decoding with input token 0.0 (word: N/A)\n",
      "Step 27: Predicted token index: 0\n",
      "Step 27: Predicted word: <unk>\n",
      "Step 28: Decoding with input token 0.0 (word: N/A)\n",
      "Step 28: Predicted token index: 0\n",
      "Step 28: Predicted word: <unk>\n",
      "Step 29: Decoding with input token 0.0 (word: N/A)\n",
      "Step 29: Predicted token index: 0\n",
      "Step 29: Predicted word: <unk>\n",
      "Step 30: Decoding with input token 0.0 (word: N/A)\n",
      "Step 30: Predicted token index: 0\n",
      "Step 30: Predicted word: <unk>\n",
      "Step 31: Decoding with input token 0.0 (word: N/A)\n",
      "Step 31: Predicted token index: 0\n",
      "Step 31: Predicted word: <unk>\n",
      "Step 32: Decoding with input token 0.0 (word: N/A)\n",
      "Step 32: Predicted token index: 0\n",
      "Step 32: Predicted word: <unk>\n",
      "Step 33: Decoding with input token 0.0 (word: N/A)\n",
      "Step 33: Predicted token index: 0\n",
      "Step 33: Predicted word: <unk>\n",
      "Step 34: Decoding with input token 0.0 (word: N/A)\n",
      "Step 34: Predicted token index: 0\n",
      "Step 34: Predicted word: <unk>\n",
      "Step 35: Decoding with input token 0.0 (word: N/A)\n",
      "Step 35: Predicted token index: 0\n",
      "Step 35: Predicted word: <unk>\n",
      "Step 36: Decoding with input token 0.0 (word: N/A)\n",
      "Step 36: Predicted token index: 0\n",
      "Step 36: Predicted word: <unk>\n",
      "Step 37: Decoding with input token 0.0 (word: N/A)\n",
      "Step 37: Predicted token index: 0\n",
      "Step 37: Predicted word: <unk>\n",
      "Step 38: Decoding with input token 0.0 (word: N/A)\n",
      "Step 38: Predicted token index: 0\n",
      "Step 38: Predicted word: <unk>\n",
      "Step 39: Decoding with input token 0.0 (word: N/A)\n",
      "Step 39: Predicted token index: 0\n",
      "Step 39: Predicted word: <unk>\n",
      "Step 40: Decoding with input token 0.0 (word: N/A)\n",
      "Step 40: Predicted token index: 0\n",
      "Step 40: Predicted word: <unk>\n",
      "Step 41: Decoding with input token 0.0 (word: N/A)\n",
      "Step 41: Predicted token index: 0\n",
      "Step 41: Predicted word: <unk>\n",
      "Step 42: Decoding with input token 0.0 (word: N/A)\n",
      "Step 42: Predicted token index: 0\n",
      "Step 42: Predicted word: <unk>\n",
      "Step 43: Decoding with input token 0.0 (word: N/A)\n",
      "Step 43: Predicted token index: 0\n",
      "Step 43: Predicted word: <unk>\n",
      "Step 44: Decoding with input token 0.0 (word: N/A)\n",
      "Step 44: Predicted token index: 0\n",
      "Step 44: Predicted word: <unk>\n",
      "Step 45: Decoding with input token 0.0 (word: N/A)\n",
      "Step 45: Predicted token index: 0\n",
      "Step 45: Predicted word: <unk>\n",
      "Step 46: Decoding with input token 0.0 (word: N/A)\n",
      "Step 46: Predicted token index: 0\n",
      "Step 46: Predicted word: <unk>\n",
      "A: \n",
      "------------------------------\n",
      "Q: What is your privacy policy?\n",
      "Step 1: Decoding with input token 3.0 (word: <start>)\n",
      "Step 1: Predicted token index: 3\n",
      "Step 1: Predicted word: <start>\n",
      "Step 2: Decoding with input token 3.0 (word: <start>)\n",
      "Step 2: Predicted token index: 3\n",
      "Step 2: Predicted word: <start>\n",
      "Step 3: Decoding with input token 3.0 (word: <start>)\n",
      "Step 3: Predicted token index: 3\n",
      "Step 3: Predicted word: <start>\n",
      "Step 4: Decoding with input token 3.0 (word: <start>)\n",
      "Step 4: Predicted token index: 3\n",
      "Step 4: Predicted word: <start>\n",
      "Step 5: Decoding with input token 3.0 (word: <start>)\n",
      "Step 5: Predicted token index: 0\n",
      "Step 5: Predicted word: <unk>\n",
      "Step 6: Decoding with input token 0.0 (word: N/A)\n",
      "Step 6: Predicted token index: 0\n",
      "Step 6: Predicted word: <unk>\n",
      "Step 7: Decoding with input token 0.0 (word: N/A)\n",
      "Step 7: Predicted token index: 0\n",
      "Step 7: Predicted word: <unk>\n",
      "Step 8: Decoding with input token 0.0 (word: N/A)\n",
      "Step 8: Predicted token index: 0\n",
      "Step 8: Predicted word: <unk>\n",
      "Step 9: Decoding with input token 0.0 (word: N/A)\n",
      "Step 9: Predicted token index: 0\n",
      "Step 9: Predicted word: <unk>\n",
      "Step 10: Decoding with input token 0.0 (word: N/A)\n",
      "Step 10: Predicted token index: 0\n",
      "Step 10: Predicted word: <unk>\n",
      "Step 11: Decoding with input token 0.0 (word: N/A)\n",
      "Step 11: Predicted token index: 0\n",
      "Step 11: Predicted word: <unk>\n",
      "Step 12: Decoding with input token 0.0 (word: N/A)\n",
      "Step 12: Predicted token index: 0\n",
      "Step 12: Predicted word: <unk>\n",
      "Step 13: Decoding with input token 0.0 (word: N/A)\n",
      "Step 13: Predicted token index: 0\n",
      "Step 13: Predicted word: <unk>\n",
      "Step 14: Decoding with input token 0.0 (word: N/A)\n",
      "Step 14: Predicted token index: 0\n",
      "Step 14: Predicted word: <unk>\n",
      "Step 15: Decoding with input token 0.0 (word: N/A)\n",
      "Step 15: Predicted token index: 0\n",
      "Step 15: Predicted word: <unk>\n",
      "Step 16: Decoding with input token 0.0 (word: N/A)\n",
      "Step 16: Predicted token index: 0\n",
      "Step 16: Predicted word: <unk>\n",
      "Step 17: Decoding with input token 0.0 (word: N/A)\n",
      "Step 17: Predicted token index: 0\n",
      "Step 17: Predicted word: <unk>\n",
      "Step 18: Decoding with input token 0.0 (word: N/A)\n",
      "Step 18: Predicted token index: 0\n",
      "Step 18: Predicted word: <unk>\n",
      "Step 19: Decoding with input token 0.0 (word: N/A)\n",
      "Step 19: Predicted token index: 0\n",
      "Step 19: Predicted word: <unk>\n",
      "Step 20: Decoding with input token 0.0 (word: N/A)\n",
      "Step 20: Predicted token index: 0\n",
      "Step 20: Predicted word: <unk>\n",
      "Step 21: Decoding with input token 0.0 (word: N/A)\n",
      "Step 21: Predicted token index: 0\n",
      "Step 21: Predicted word: <unk>\n",
      "Step 22: Decoding with input token 0.0 (word: N/A)\n",
      "Step 22: Predicted token index: 0\n",
      "Step 22: Predicted word: <unk>\n",
      "Step 23: Decoding with input token 0.0 (word: N/A)\n",
      "Step 23: Predicted token index: 0\n",
      "Step 23: Predicted word: <unk>\n",
      "Step 24: Decoding with input token 0.0 (word: N/A)\n",
      "Step 24: Predicted token index: 0\n",
      "Step 24: Predicted word: <unk>\n",
      "Step 25: Decoding with input token 0.0 (word: N/A)\n",
      "Step 25: Predicted token index: 0\n",
      "Step 25: Predicted word: <unk>\n",
      "Step 26: Decoding with input token 0.0 (word: N/A)\n",
      "Step 26: Predicted token index: 0\n",
      "Step 26: Predicted word: <unk>\n",
      "Step 27: Decoding with input token 0.0 (word: N/A)\n",
      "Step 27: Predicted token index: 0\n",
      "Step 27: Predicted word: <unk>\n",
      "Step 28: Decoding with input token 0.0 (word: N/A)\n",
      "Step 28: Predicted token index: 0\n",
      "Step 28: Predicted word: <unk>\n",
      "Step 29: Decoding with input token 0.0 (word: N/A)\n",
      "Step 29: Predicted token index: 0\n",
      "Step 29: Predicted word: <unk>\n",
      "Step 30: Decoding with input token 0.0 (word: N/A)\n",
      "Step 30: Predicted token index: 0\n",
      "Step 30: Predicted word: <unk>\n",
      "Step 31: Decoding with input token 0.0 (word: N/A)\n",
      "Step 31: Predicted token index: 0\n",
      "Step 31: Predicted word: <unk>\n",
      "Step 32: Decoding with input token 0.0 (word: N/A)\n",
      "Step 32: Predicted token index: 0\n",
      "Step 32: Predicted word: <unk>\n",
      "Step 33: Decoding with input token 0.0 (word: N/A)\n",
      "Step 33: Predicted token index: 0\n",
      "Step 33: Predicted word: <unk>\n",
      "Step 34: Decoding with input token 0.0 (word: N/A)\n",
      "Step 34: Predicted token index: 0\n",
      "Step 34: Predicted word: <unk>\n",
      "Step 35: Decoding with input token 0.0 (word: N/A)\n",
      "Step 35: Predicted token index: 0\n",
      "Step 35: Predicted word: <unk>\n",
      "Step 36: Decoding with input token 0.0 (word: N/A)\n",
      "Step 36: Predicted token index: 0\n",
      "Step 36: Predicted word: <unk>\n",
      "Step 37: Decoding with input token 0.0 (word: N/A)\n",
      "Step 37: Predicted token index: 0\n",
      "Step 37: Predicted word: <unk>\n",
      "Step 38: Decoding with input token 0.0 (word: N/A)\n",
      "Step 38: Predicted token index: 0\n",
      "Step 38: Predicted word: <unk>\n",
      "Step 39: Decoding with input token 0.0 (word: N/A)\n",
      "Step 39: Predicted token index: 0\n",
      "Step 39: Predicted word: <unk>\n",
      "Step 40: Decoding with input token 0.0 (word: N/A)\n",
      "Step 40: Predicted token index: 0\n",
      "Step 40: Predicted word: <unk>\n",
      "Step 41: Decoding with input token 0.0 (word: N/A)\n",
      "Step 41: Predicted token index: 0\n",
      "Step 41: Predicted word: <unk>\n",
      "Step 42: Decoding with input token 0.0 (word: N/A)\n",
      "Step 42: Predicted token index: 0\n",
      "Step 42: Predicted word: <unk>\n",
      "Step 43: Decoding with input token 0.0 (word: N/A)\n",
      "Step 43: Predicted token index: 0\n",
      "Step 43: Predicted word: <unk>\n",
      "Step 44: Decoding with input token 0.0 (word: N/A)\n",
      "Step 44: Predicted token index: 0\n",
      "Step 44: Predicted word: <unk>\n",
      "Step 45: Decoding with input token 0.0 (word: N/A)\n",
      "Step 45: Predicted token index: 0\n",
      "Step 45: Predicted word: <unk>\n",
      "Step 46: Decoding with input token 0.0 (word: N/A)\n",
      "Step 46: Predicted token index: 0\n",
      "Step 46: Predicted word: <unk>\n",
      "A: \n",
      "------------------------------\n",
      "Q: Can I return a product if it was purchased as a gift?\n",
      "Step 1: Decoding with input token 3.0 (word: <start>)\n",
      "Step 1: Predicted token index: 3\n",
      "Step 1: Predicted word: <start>\n",
      "Step 2: Decoding with input token 3.0 (word: <start>)\n",
      "Step 2: Predicted token index: 3\n",
      "Step 2: Predicted word: <start>\n",
      "Step 3: Decoding with input token 3.0 (word: <start>)\n",
      "Step 3: Predicted token index: 3\n",
      "Step 3: Predicted word: <start>\n",
      "Step 4: Decoding with input token 3.0 (word: <start>)\n",
      "Step 4: Predicted token index: 3\n",
      "Step 4: Predicted word: <start>\n",
      "Step 5: Decoding with input token 3.0 (word: <start>)\n",
      "Step 5: Predicted token index: 0\n",
      "Step 5: Predicted word: <unk>\n",
      "Step 6: Decoding with input token 0.0 (word: N/A)\n",
      "Step 6: Predicted token index: 0\n",
      "Step 6: Predicted word: <unk>\n",
      "Step 7: Decoding with input token 0.0 (word: N/A)\n",
      "Step 7: Predicted token index: 0\n",
      "Step 7: Predicted word: <unk>\n",
      "Step 8: Decoding with input token 0.0 (word: N/A)\n",
      "Step 8: Predicted token index: 0\n",
      "Step 8: Predicted word: <unk>\n",
      "Step 9: Decoding with input token 0.0 (word: N/A)\n",
      "Step 9: Predicted token index: 0\n",
      "Step 9: Predicted word: <unk>\n",
      "Step 10: Decoding with input token 0.0 (word: N/A)\n",
      "Step 10: Predicted token index: 0\n",
      "Step 10: Predicted word: <unk>\n",
      "Step 11: Decoding with input token 0.0 (word: N/A)\n",
      "Step 11: Predicted token index: 0\n",
      "Step 11: Predicted word: <unk>\n",
      "Step 12: Decoding with input token 0.0 (word: N/A)\n",
      "Step 12: Predicted token index: 0\n",
      "Step 12: Predicted word: <unk>\n",
      "Step 13: Decoding with input token 0.0 (word: N/A)\n",
      "Step 13: Predicted token index: 0\n",
      "Step 13: Predicted word: <unk>\n",
      "Step 14: Decoding with input token 0.0 (word: N/A)\n",
      "Step 14: Predicted token index: 0\n",
      "Step 14: Predicted word: <unk>\n",
      "Step 15: Decoding with input token 0.0 (word: N/A)\n",
      "Step 15: Predicted token index: 0\n",
      "Step 15: Predicted word: <unk>\n",
      "Step 16: Decoding with input token 0.0 (word: N/A)\n",
      "Step 16: Predicted token index: 0\n",
      "Step 16: Predicted word: <unk>\n",
      "Step 17: Decoding with input token 0.0 (word: N/A)\n",
      "Step 17: Predicted token index: 0\n",
      "Step 17: Predicted word: <unk>\n",
      "Step 18: Decoding with input token 0.0 (word: N/A)\n",
      "Step 18: Predicted token index: 0\n",
      "Step 18: Predicted word: <unk>\n",
      "Step 19: Decoding with input token 0.0 (word: N/A)\n",
      "Step 19: Predicted token index: 0\n",
      "Step 19: Predicted word: <unk>\n",
      "Step 20: Decoding with input token 0.0 (word: N/A)\n",
      "Step 20: Predicted token index: 0\n",
      "Step 20: Predicted word: <unk>\n",
      "Step 21: Decoding with input token 0.0 (word: N/A)\n",
      "Step 21: Predicted token index: 0\n",
      "Step 21: Predicted word: <unk>\n",
      "Step 22: Decoding with input token 0.0 (word: N/A)\n",
      "Step 22: Predicted token index: 0\n",
      "Step 22: Predicted word: <unk>\n",
      "Step 23: Decoding with input token 0.0 (word: N/A)\n",
      "Step 23: Predicted token index: 0\n",
      "Step 23: Predicted word: <unk>\n",
      "Step 24: Decoding with input token 0.0 (word: N/A)\n",
      "Step 24: Predicted token index: 0\n",
      "Step 24: Predicted word: <unk>\n",
      "Step 25: Decoding with input token 0.0 (word: N/A)\n",
      "Step 25: Predicted token index: 0\n",
      "Step 25: Predicted word: <unk>\n",
      "Step 26: Decoding with input token 0.0 (word: N/A)\n",
      "Step 26: Predicted token index: 0\n",
      "Step 26: Predicted word: <unk>\n",
      "Step 27: Decoding with input token 0.0 (word: N/A)\n",
      "Step 27: Predicted token index: 0\n",
      "Step 27: Predicted word: <unk>\n",
      "Step 28: Decoding with input token 0.0 (word: N/A)\n",
      "Step 28: Predicted token index: 0\n",
      "Step 28: Predicted word: <unk>\n",
      "Step 29: Decoding with input token 0.0 (word: N/A)\n",
      "Step 29: Predicted token index: 0\n",
      "Step 29: Predicted word: <unk>\n",
      "Step 30: Decoding with input token 0.0 (word: N/A)\n",
      "Step 30: Predicted token index: 0\n",
      "Step 30: Predicted word: <unk>\n",
      "Step 31: Decoding with input token 0.0 (word: N/A)\n",
      "Step 31: Predicted token index: 0\n",
      "Step 31: Predicted word: <unk>\n",
      "Step 32: Decoding with input token 0.0 (word: N/A)\n",
      "Step 32: Predicted token index: 0\n",
      "Step 32: Predicted word: <unk>\n",
      "Step 33: Decoding with input token 0.0 (word: N/A)\n",
      "Step 33: Predicted token index: 0\n",
      "Step 33: Predicted word: <unk>\n",
      "Step 34: Decoding with input token 0.0 (word: N/A)\n",
      "Step 34: Predicted token index: 0\n",
      "Step 34: Predicted word: <unk>\n",
      "Step 35: Decoding with input token 0.0 (word: N/A)\n",
      "Step 35: Predicted token index: 0\n",
      "Step 35: Predicted word: <unk>\n",
      "Step 36: Decoding with input token 0.0 (word: N/A)\n",
      "Step 36: Predicted token index: 0\n",
      "Step 36: Predicted word: <unk>\n",
      "Step 37: Decoding with input token 0.0 (word: N/A)\n",
      "Step 37: Predicted token index: 0\n",
      "Step 37: Predicted word: <unk>\n",
      "Step 38: Decoding with input token 0.0 (word: N/A)\n",
      "Step 38: Predicted token index: 0\n",
      "Step 38: Predicted word: <unk>\n",
      "Step 39: Decoding with input token 0.0 (word: N/A)\n",
      "Step 39: Predicted token index: 0\n",
      "Step 39: Predicted word: <unk>\n",
      "Step 40: Decoding with input token 0.0 (word: N/A)\n",
      "Step 40: Predicted token index: 0\n",
      "Step 40: Predicted word: <unk>\n",
      "Step 41: Decoding with input token 0.0 (word: N/A)\n",
      "Step 41: Predicted token index: 0\n",
      "Step 41: Predicted word: <unk>\n",
      "Step 42: Decoding with input token 0.0 (word: N/A)\n",
      "Step 42: Predicted token index: 0\n",
      "Step 42: Predicted word: <unk>\n",
      "Step 43: Decoding with input token 0.0 (word: N/A)\n",
      "Step 43: Predicted token index: 0\n",
      "Step 43: Predicted word: <unk>\n",
      "Step 44: Decoding with input token 0.0 (word: N/A)\n",
      "Step 44: Predicted token index: 0\n",
      "Step 44: Predicted word: <unk>\n",
      "Step 45: Decoding with input token 0.0 (word: N/A)\n",
      "Step 45: Predicted token index: 0\n",
      "Step 45: Predicted word: <unk>\n",
      "Step 46: Decoding with input token 0.0 (word: N/A)\n",
      "Step 46: Predicted token index: 0\n",
      "Step 46: Predicted word: <unk>\n",
      "A: \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"How can I reset my password?\",\n",
    "    \"What payment methods do you accept?\",\n",
    "    \"How do I update my account information?\",\n",
    "    \"What is your privacy policy?\",\n",
    "    \"Can I return a product if it was purchased as a gift?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A:\", answer_question(q))\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_ceia_18co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
