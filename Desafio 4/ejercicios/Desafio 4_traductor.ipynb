{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### Datos\n",
    "El objecto es utilizar datos disponibles del Tatoeba Project de traducciones de texto en diferentes idiomas. Se construirá un modelo traductor de inglés a español seq2seq utilizando encoder-decoder.\\\n",
    "[LINK](https://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, LSTM, SimpleRNN, Input, Embedding\n",
    "from tensorflow.keras.utils import pad_sequences, plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda nueva\n",
    "!pip install transformers sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RHNkUaPp6aYq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset ya se encuentra descargado\n"
     ]
    }
   ],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "\n",
    "import os\n",
    "if os.access('spa-eng', os.F_OK) is False:\n",
    "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
    "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "    !unzip -q spa-eng.zip \n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-9aNLZBDtA5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 10000\n"
     ]
    }
   ],
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = \"./spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 10000\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    # el tabulador señaliza la separación entre las oraciones \n",
    "    # en ambos idiomas\n",
    "    if '\\t' not in line: \n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "93IGMKFb73q7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A deal is a deal.',\n",
       " 'Un trato es un trato. <eos>',\n",
       " '<sos> Un trato es un trato.')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5WAZGOTfGyha"
   },
   "outputs": [],
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 7000\n",
    "# Vamos a necesitar un tokenizador para cada idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "eF1W6peoFGXA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 4948\n",
      "Sentencia de entrada más larga: 32\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# tokenizador de inglés\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "zBzdKiTVIBYY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 7731\n",
      "Sentencia de salida más larga: 36\n",
      "Sentencia de salida más larga: 7000\n"
     ]
    }
   ],
   "source": [
    "# tokenizador de español\n",
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "#num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) \n",
    "num_words_output = min(MAX_VOCAB_SIZE, len(word2idx_outputs) + 1)\n",
    "# Se suma 1 para incluir el token de palabra desconocida\n",
    "\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)\n",
    "print(\"Sentencia de salida más larga:\", num_words_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqb8ZJ4sJHgv"
   },
   "source": [
    "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "pgLC706EQx3p"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
    "# a la mitad:\n",
    "max_input_len = 16\n",
    "max_out_len = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGOn9N57IuYz"
   },
   "source": [
    "A la hora de realiza padding es importante tener en cuenta que en el encoder los ceros se agregan al comienzo y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "q0Ob4hAWJkcv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 10000\n",
      "encoder_input_sequences shape: (10000, 16)\n",
      "decoder_input_sequences shape: (10000, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK4blEEsRQv3"
   },
   "source": [
    "La última capa del modelo (softmax) necesita que los valores de salida\n",
    "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
    "Se utiliza \"decoder_output_sequences\" con la misma estrategia con que se transformó la entrada del decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "3toZyIVEOC18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18, 7000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Jlnzm7oOuC4z"
   },
   "outputs": [],
   "source": [
    "# Descargar los embeddings desde un google drive (es la forma más rápida)\n",
    "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
    "# disponibles descargar de la página oficial como se explica en el siguiente bloque de código\n",
    "!pip install --upgrade --no-cache-dir gdown --quiet\n",
    "import os\n",
    "import gdown\n",
    "#!gdown --id 1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94 -O gloveembedding.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de que gdown de algún error de permisos intentar descargar los\n",
    "# embeddings con curl:\n",
    "\n",
    "#!curl -L -o 'gloveembedding.pkl' 'https://drive.google.com/u/0/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download&confirm=t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ZgqtV8GpkSc8"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding (1).pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Mosj2-x-kXBK"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de RAM se utilizarán los embeddings de Glove de dimension 50\n",
    "model_embeddings = GloveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "b9FS8ca1ke_B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 47\n"
     ]
    }
   ],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en inglés\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "#nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "FpzJODHBlAtE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4949, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión de los embeddings de la secuencia en inglés\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "3fm3HCLMPSG-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "t_urD1qO2kOx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">247,450</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">896,000</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7000</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">903,000</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │    \u001b[38;5;34m247,450\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m896,000\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │     \u001b[38;5;34m91,648\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m), │    \u001b[38;5;34m131,584\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m7000\u001b[0m)  │    \u001b[38;5;34m903,000\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,269,682</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,269,682\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,022,232</span> (7.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,022,232\u001b[0m (7.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">247,450</span> (966.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m247,450\u001b[0m (966.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "n_units = 128\n",
    "\n",
    "# define training encoder\n",
    "encoder_inputs = Input(shape=(max_input_len,))\n",
    "\n",
    "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "\n",
    "encoder_embedding_layer = Embedding(\n",
    "          input_dim=nb_words,  # definido en el Tokenizador\n",
    "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
    "          input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n",
    "          weights=[embedding_matrix],  # matrix de embeddings\n",
    "          trainable=False)      # marcar como layer no entrenable\n",
    "\n",
    "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "encoder = LSTM(n_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define training decoder\n",
    "decoder_inputs = Input(shape=(max_out_len,))\n",
    "decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# Dense\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "2ljAyiBbG10U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo completo (encoder+decoder) para poder entrenar\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "s1Wc1pnhIKJ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo solo encoder\n",
    "\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "plot_model(encoder_model, to_file='encoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "L_xanat4INez"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo solo decoder (para realizar inferencia)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
    "# que es la realimentación de la palabra anterior\n",
    "# por lo que hay que modificar el input shape de la layer de Embedding\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4949"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding_matrix.shape[0] \n",
    "max(word2idx_inputs.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "VnlIx1Vezjwc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - accuracy: 0.6000 - loss: 4.2993 - val_accuracy: 0.6901 - val_loss: 2.1489\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.6748 - loss: 2.2608 - val_accuracy: 0.6951 - val_loss: 2.0769\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - accuracy: 0.6778 - loss: 2.1997 - val_accuracy: 0.7013 - val_loss: 2.0022\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.6901 - loss: 2.0574 - val_accuracy: 0.7047 - val_loss: 1.9450\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 61ms/step - accuracy: 0.6978 - loss: 1.9595 - val_accuracy: 0.7089 - val_loss: 1.8980\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=5, # 15 inicialmente \n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "OVz1uug_zu2J"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "jnkl3mSpsU_7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStep 1:\\nA deal is a deal -> Encoder -> enc(h1,c1)\\n\\nenc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\\n\\nstep 2:\\ndec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\\n\\nstep 3:\\ndec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\\n\\nstep 4:\\ndec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\\n\\nstep 5:\\ndec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\\n\\nstep 6:\\ndec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 1:\n",
    "A deal is a deal -> Encoder -> enc(h1,c1)\n",
    "\n",
    "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
    "\n",
    "step 2:\n",
    "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
    "\n",
    "step 3:\n",
    "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
    "\n",
    "step 4:\n",
    "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
    "\n",
    "step 5:\n",
    "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
    "\n",
    "step 6:\n",
    "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar los conversores de índice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # Se obtiene el índice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    \n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar idx a palabra\n",
    "        word = ''        \n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dada la última predicción\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "ZhGVjLKcunxW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "-\n",
      "Input: Mary wants to buy a dress.\n",
      "Response: él no no no se dijo a mary\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "KYZ1Q_Z_2G4m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: My mother say hi.\n",
      "Representacion en vector de tokens de ids [16, 240, 129]\n",
      "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0  16 240 129]]\n",
      "Input: My mother say hi.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Response: él no no es\n"
     ]
    }
   ],
   "source": [
    "input_test = \"My mother say hi.\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "\n",
    "print('Input:', input_test)\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkOjSJweqdF8"
   },
   "source": [
    "### 6 - Conclusión\n",
    "A primera vista parece que el modelo tendría que funcionar muy bien por el accuracy alcanzado. La realidad es que las respuestas no tienen que ver demasiado con la pregunta/traducción pero la respuesta en si tiene bastante coherencia.\\\n",
    "Para poder mejorar el modelo haría falta poder consumir todo el dataset y todo el vocabulario, pero la cantidad de RAM no es suficiente.\\\n",
    "Este problema se resuelve con:\n",
    "- Utilizando un DataGenerator para no levantar todo el dataset junto en el entrenamiento.\n",
    "- Transfer learning evitando tener que entrenar todo el modelo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Inferencia con Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (80.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.68.2)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.9)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Celda nueva\n",
    "#!pip install transformers sentencepiece --quiet\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ia_ceia_18co/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Celda nueva\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el pipeline de traducción.\n",
    "# Esto descargará el modelo y el tokenizador pre-entrenados la primera vez que se ejecute.\n",
    "translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Usando el modelo LSTM entrenado desde cero ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Input: Tom is naked.\n",
      "Response (LSTM): tom es la noche\n",
      "--------------------\n",
      "\n",
      "--- Usando el modelo de Transfer Learning (Helsinki-NLP) ---\n",
      "Input: Tom is naked.\n",
      "Response (Transfer Learning): Tom está desnudo.\n"
     ]
    }
   ],
   "source": [
    "# Usemos la misma oración aleatoria que antes para comparar\n",
    "i = np.random.choice(len(input_sentences))\n",
    "input_text = input_sentences[i]\n",
    "\n",
    "print(\"--- Usando el modelo LSTM entrenado desde cero ---\")\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "original_translation = translate_sentence(input_seq)\n",
    "print('Input:', input_text)\n",
    "print('Response (LSTM):', original_translation)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "print(\"\\n--- Usando el modelo de Transfer Learning (Helsinki-NLP) ---\")\n",
    "transfer_learning_translation = translator(input_text)\n",
    "\n",
    "print('Input:', input_text)\n",
    "# El resultado es una lista de diccionarios, extraemos el texto de la traducción\n",
    "print('Response (Transfer Learning):', transfer_learning_translation[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prueba manual con Transfer Learning ---\n",
      "Input: My mother say hi.\n",
      "Response (Transfer Learning): Mi madre me manda saludos.\n"
     ]
    }
   ],
   "source": [
    "input_test = \"My mother say hi.\"\n",
    "\n",
    "print(\"\\n--- Prueba manual con Transfer Learning ---\")\n",
    "transfer_learning_translation = translator(input_test)\n",
    "\n",
    "print('Input:', input_test)\n",
    "print('Response (Transfer Learning):', transfer_learning_translation[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSy0kaSKuC4-"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ia_ceia_18co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
